{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/alihashemi1376/pytorch-onnx-cifar10-resnet18?scriptVersionId=209302877\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install torchsummary ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install onnxruntime   ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T08:45:15.806568Z","iopub.execute_input":"2024-11-24T08:45:15.806916Z","iopub.status.idle":"2024-11-24T08:45:25.574569Z","shell.execute_reply.started":"2024-11-24T08:45:15.806886Z","shell.execute_reply":"2024-11-24T08:45:25.57347Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt \nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset,random_split,DataLoader\nfrom torch.optim.lr_scheduler import ExponentialLR, CosineAnnealingWarmRestarts\nfrom torchvision import transforms, models,datasets\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport torchvision.transforms as transforms\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt \nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset,random_split\nfrom torch.optim.lr_scheduler import ExponentialLR, CosineAnnealingWarmRestarts,PolynomialLR\nfrom torchvision import transforms, models \nimport warnings\nwarnings.filterwarnings(\"ignore\") \nfrom torchvision import models\nfrom torchsummary import summary   \nimport cv2 \nimport onnx\nimport onnxruntime as ort\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T08:45:32.433562Z","iopub.execute_input":"2024-11-24T08:45:32.434522Z","iopub.status.idle":"2024-11-24T08:45:32.470957Z","shell.execute_reply.started":"2024-11-24T08:45:32.434483Z","shell.execute_reply":"2024-11-24T08:45:32.470331Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available else 'cpu' ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:36:18.626086Z","iopub.execute_input":"2024-11-24T07:36:18.626894Z","iopub.status.idle":"2024-11-24T07:36:18.630603Z","shell.execute_reply.started":"2024-11-24T07:36:18.62686Z","shell.execute_reply":"2024-11-24T07:36:18.629687Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Set batch size\nbatch_size = 64\n\n# Define transformations\ntransform = transforms.Compose([\n    transforms.ToTensor(),  # Convert images to PyTorch tensors\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize to [-1, 1]\n])\n\n# Load CIFAR-10 dataset\ntrain_dataset = datasets.CIFAR10(\n    root='./data',  # Directory to store dataset\n    train=True,  # Load training set\n    download=True,  # Download if not already available\n    transform=transform  # Apply transformations\n)\n\ntest_dataset = datasets.CIFAR10(\n    root='./data',\n    train=False,  # Load test set\n    download=True,\n    transform=transform\n)\n\n# Create DataLoaders\ntrain_loader = DataLoader(\n    dataset=train_dataset,\n    batch_size=batch_size,\n    shuffle=True,  # Shuffle training data\n    num_workers=2  # Use multiple workers for loading data\n)\n\ntest_loader = DataLoader(\n    dataset=test_dataset,\n    batch_size=batch_size,\n    shuffle=False,  # No need to shuffle test data\n    num_workers=2\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:32:28.643644Z","iopub.execute_input":"2024-11-24T07:32:28.643958Z","iopub.status.idle":"2024-11-24T07:32:30.288537Z","shell.execute_reply.started":"2024-11-24T07:32:28.643932Z","shell.execute_reply":"2024-11-24T07:32:30.287604Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ResNet18(nn.Module):\n    def __init__(self,num_class = 2):\n        super(ResNet18,self).__init__()\n\n        self.model = models.resnet18(True) \n        self.freez()\n        self.fine_tune() \n\n    def freez (self):\n        for param in self.model.parameters():\n            param.requires_grad = False\n\n       \n          \n    \n    def fine_tune(self):\n            \n            \n            \n            \n            for param in self.model.layer4.parameters():\n                param.requires_grad = True  \n            self.model.fc = nn.Sequential(\n                 nn.Dropout(p =0.2),\n                 nn.Linear(512,256),\n                 nn.ReLU(),\n                 nn.Linear(256,10),\n                 nn.Softmax(dim = 1)\n                 )\n    def forward(self,x):\n        \n        return self.model(x)\n\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:50:29.715331Z","iopub.execute_input":"2024-11-24T09:50:29.716038Z","iopub.status.idle":"2024-11-24T09:50:29.722017Z","shell.execute_reply.started":"2024-11-24T09:50:29.716006Z","shell.execute_reply":"2024-11-24T09:50:29.721073Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def fit(clf,\n        train_loader,\n        optimizer,\n        criterian,\n        scheduler):\n\n    clf.train()\n    training_loss_running = 0\n    training_correct_running = 0\n    total = 0\n    counter = 0\n    for i,data in enumerate(train_loader):\n        counter += 1\n        data,label = data[0].to(device),data[1].to(device)\n        #data = data.reshape(-1,28*28)\n        total += label.size(0)\n        optimizer.zero_grad()\n        out = clf(data)            \n        loss = criterian(out, label)                \n        training_loss_running += loss.item()\n        _,pred = torch.max(out.data,1)\n        training_correct_running += (pred == label).sum().item()\n        loss.backward()\n        optimizer.step()\n    scheduler.step() \n    train_loss = training_loss_running / counter\n    train_accuracy = 100. * training_correct_running / total\n    print(optimizer.param_groups[0]['lr'])\n    return train_loss, train_accuracy     \n\ndef validation (clf,validation_loader,criterian,epoch):\n    clf.eval()\n    valid_loss_running = 0\n    valid_acc_running = 0\n    total = 0\n    counter = 0\n    for i,data in enumerate(validation_loader):\n        counter += 1\n        data,label = data[0].to(device),data[1].to(device)\n        #data = data.reshape(-1,28*28)\n        total += label.size(0)\n        out = clf(data)\n        loss = criterian(out, label)\n        valid_loss_running += loss.item()\n        _,pred = torch.max(out.data,1)\n        valid_acc_running += (pred == label).sum().item()\n\n    valid_loss = valid_loss_running / counter\n    valid_acc = 100. * valid_acc_running / total  \n      \n\n    return valid_loss,valid_acc\n       \ndef train (hyparam,train_loader,val_loader):\n\n    clf = ResNet18().to(device)\n    #optimizer = torch.optim.Adam(clf.parameters(), lr =hyparam['lr'])\n    optimizer = torch.optim.Adam(clf.parameters(), lr=hyparam['lr'])\n    criterian = nn.CrossEntropyLoss()\n    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=50, T_mult=1)\n    #scheduler = PolynomialLR(optimizer,  total_iters=5, power=1)\n    train_loss =[]\n    train_acc =[]\n    val_loss =[]\n    val_acc = []\n    \n    for epoch in range(hyparam['epoch']):\n        print(f\"Epoch {epoch+1} of {hyparam['epoch']}\")\n        training_loss,training_acc = fit(clf,train_loader,optimizer,criterian,scheduler)\n        validation_loss,validation_acc = validation(clf,val_loader,criterian,epoch)\n\n        train_loss.append(training_loss)\n        train_acc.append(training_acc)\n\n        val_loss.append(validation_loss)\n        val_acc.append(validation_acc)\n\n        \n\n       \n        \n    \n        print(f\"Train Loss: {training_loss:.4f}, Train Acc: {training_acc:.2f},\\\n         Val Loss: {validation_loss:.4f}, Val Acc: {validation_acc:.2f}\")\n\n\n\n      \n    return clf,train_loss,train_acc,val_loss,val_acc\n        \n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:50:34.995846Z","iopub.execute_input":"2024-11-24T09:50:34.996208Z","iopub.status.idle":"2024-11-24T09:50:35.008266Z","shell.execute_reply.started":"2024-11-24T09:50:34.996148Z","shell.execute_reply":"2024-11-24T09:50:35.007405Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"hparams = {'batch_size': 256, 'lr': 0.4e-4, 'epoch': 32} #6e-4      \nclf,train_loss,train_acc,val_loss,val_acc = train(hparams,train_loader,test_loader)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T10:35:53.063261Z","iopub.execute_input":"2024-11-24T10:35:53.063626Z","iopub.status.idle":"2024-11-24T10:42:23.027335Z","shell.execute_reply.started":"2024-11-24T10:35:53.063597Z","shell.execute_reply":"2024-11-24T10:42:23.026242Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Convert Model into ONNX and Inference**","metadata":{}},{"cell_type":"code","source":"\ndummy_input = torch.randn(64, 3, 32, 32).to('cuda')  # (batch_size, channels, height, width)\ndummy_input = torch.randn(1,3,32,32).to('cuda')\ntorch.onnx.export(clf, dummy_input, \"model.onnx\", \n                  input_names=[\"input\"], output_names=[\"output\"], \n                  dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}})\n\nmodel_onnx_cpu = ort.InferenceSession('model.onnx', providers=['CPUExecutionProvider'])\ndata_n = data.cpu().numpy().astype(np.float32)\nort_inputs = {model_onnx_cpu.get_inputs()[0].name: data_n}\npredict_onnx = model_onnx_cpu.run(None, ort_inputs)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T10:58:21.382158Z","iopub.execute_input":"2024-11-24T10:58:21.382556Z","iopub.status.idle":"2024-11-24T10:58:22.096784Z","shell.execute_reply.started":"2024-11-24T10:58:21.382526Z","shell.execute_reply":"2024-11-24T10:58:22.095984Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Convert Model into .pt and .pth**","metadata":{}},{"cell_type":"code","source":"torch.save(clf, 'model.pt')\nmodel_pt = torch.load('model.pt') ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:01:13.201158Z","iopub.execute_input":"2024-11-24T11:01:13.201969Z","iopub.status.idle":"2024-11-24T11:01:13.385585Z","shell.execute_reply.started":"2024-11-24T11:01:13.201936Z","shell.execute_reply":"2024-11-24T11:01:13.384616Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = ResNet18().to('cuda') \nmodel.load_state_dict(torch.load('model.pth', weights_only=True))\ntorch.save(clf.state_dict(),'model.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:01:55.000603Z","iopub.execute_input":"2024-11-24T11:01:55.000951Z","iopub.status.idle":"2024-11-24T11:01:55.365799Z","shell.execute_reply.started":"2024-11-24T11:01:55.000921Z","shell.execute_reply":"2024-11-24T11:01:55.365Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data,label = next(iter(train_loader))\ndata = data.to('cuda')\nlabel = label.to('cuda')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T10:28:30.078086Z","iopub.execute_input":"2024-11-24T10:28:30.078736Z","iopub.status.idle":"2024-11-24T10:28:30.274608Z","shell.execute_reply.started":"2024-11-24T10:28:30.078702Z","shell.execute_reply":"2024-11-24T10:28:30.273363Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Calculating ACC Models**","metadata":{}},{"cell_type":"code","source":"def acc(predict,label):\n    pre = torch.max(predict,1)[1]\n    return ((pre == label).sum() / label.shape[0]).item()\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:02:09.054734Z","iopub.execute_input":"2024-11-24T11:02:09.055529Z","iopub.status.idle":"2024-11-24T11:02:09.059615Z","shell.execute_reply.started":"2024-11-24T11:02:09.055481Z","shell.execute_reply":"2024-11-24T11:02:09.058728Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict_pt = model_pt(data)\npredict_pth = model(data)\nacc_pt = acc(predict_pt,label)\nacc_pth = acc(predict_pth,label)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:02:28.920309Z","iopub.execute_input":"2024-11-24T11:02:28.920634Z","iopub.status.idle":"2024-11-24T11:02:28.936902Z","shell.execute_reply.started":"2024-11-24T11:02:28.920607Z","shell.execute_reply":"2024-11-24T11:02:28.936219Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('ONNX-Model',acc(torch.tensor(predict_onnx[0]).to('cuda'),label)) \nprint('pt-Model',acc_pt)\nprint('pth-Model',acc_pth) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:05:30.019053Z","iopub.execute_input":"2024-11-24T11:05:30.019424Z","iopub.status.idle":"2024-11-24T11:05:30.025259Z","shell.execute_reply.started":"2024-11-24T11:05:30.019392Z","shell.execute_reply":"2024-11-24T11:05:30.024438Z"}},"outputs":[],"execution_count":null}]}